# dbt-bigquery
## Case Study: dbt with BigQuery Integration

<p align="center">
<a href="https://www.linkedin.com/in/danilo-gaspar98/">
<img alt="Danilo Gaspar" src="https://img.shields.io/badge/LinkedIn-Danilo%20Gaspar-blue" />
</a>
<img alt="License" src="https://img.shields.io/badge/license-MIT-blue">
</p>

## ğŸš€ Projeto de Pipeline de Dados com dbt
Este projeto demonstra a construÃ§Ã£o de uma pipeline de dados robusta e automatizada, utilizando ferramentas modernas para transformaÃ§Ã£o e orquestraÃ§Ã£o de dados.

A soluÃ§Ã£o integra:

- **dbt (Data Build Tool)**: Para modelagem e transformaÃ§Ã£o de dados.
- **Google Cloud Platform (GCP)**: Como data warehouse, utilizando o BigQuery.
- **GitHub Actions**: Para automaÃ§Ã£o de CI/CD.

![Evidencia](https://raw.githubusercontent.com/dangspr/dbt-bigquery/main/dbt_docs.png)

## ğŸ§± Arquitetura da SoluÃ§Ã£o
A arquitetura Ã© composta pelos seguintes componentes:

### ğŸ”§ dbt (Data Build Tool)
Ferramenta de transformaÃ§Ã£o de dados baseada em SQL, que oferece:
- ModularizaÃ§Ã£o e reutilizaÃ§Ã£o de modelos.
- AplicaÃ§Ã£o de testes automÃ¡ticos.
- DocumentaÃ§Ã£o integrada.

### â˜ï¸ Google Cloud Platform (GCP)
Plataforma de nuvem utilizada para:
- Armazenamento e processamento de dados.
- BigQuery como DW, onde tabelas e views sÃ£o materializadas.

### ğŸ“‚ GitHub
RepositÃ³rio para versionamento de cÃ³digo, contendo:
- Modelos SQL.
- Arquivos de schema (.yml).
- ConfiguraÃ§Ãµes do projeto dbt.

### âš™ï¸ GitHub Actions
Ferramenta de CI/CD que automatiza:
- Deploy

## ğŸ“ Estrutura do Projeto 
A nova estrutura segue a arquitetura Medallion, separando os modelos em camadas para clareza e governanÃ§a de dados.

```
â”œâ”€â”€ dbt_project.yml        # ConfiguraÃ§Ãµes globais do projeto dbt
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ raw/               # Camada Raw: Dados brutos, imutÃ¡veis e de origem
â”‚   â”‚   â”œâ”€â”€ triggo_shop.sql
â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”œâ”€â”€ stg/               # Camada Staging: Dados limpos, padronizados e intermediÃ¡rios
â”‚   â”‚   â”œâ”€â”€ customers.sql
â”‚   â”‚   â”œâ”€â”€ orders.sql
â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â””â”€â”€ refined/           # Camada Refined: Dados agregados, prontos para anÃ¡lise de negÃ³cio
â”‚       â”œâ”€â”€ customer_orders_summary.sql
â”‚       â””â”€â”€ schema.yml
â””â”€â”€ ...
```

## ğŸ“ Principais Arquivos
- **dbt_project.yml**: Define configuraÃ§Ãµes como a materializaÃ§Ã£o padrÃ£o e o perfil de conexÃ£o para cada camada.
- **models/*.sql**: Arquivos com os modelos SQL, organizados por camada.
- **models/*.yml**: Arquivos de schema com testes (unique, not_null, etc.) e documentaÃ§Ã£o, localizados junto aos modelos que descrevem.

## ğŸ” Exemplo do Fluxo de TransformaÃ§Ã£o
Este projeto transforma dados brutos de pedidos e clientes em uma tabela analÃ­tica, seguindo o fluxo de raw -> stg -> refined.

### ğŸ“Œ Camada raw: triggo_shop
Fonte de dados brutos do projeto. ContÃ©m a tabela estÃ¡tica com dados de clientes e pedidos.

```sql
-- models/raw/triggo_shop.sql
{{
  config(
    materialized='table'
  )
}}

select
    id,
    first_name,
    last_name,
    user_id,
    order_date,
    status
from (
    select * from unnest([
        struct(1 as id, 'Enio' as first_name, 'Tanner' as last_name, 1 as user_id, '2023-01-10' as order_date, 'delivered' as status),
        struct(2 as id, 'Galego' as first_name, 'Manson' as last_name, 1 as user_id, '2023-01-15' as order_date, 'shipped' as status),
        struct(3 as id, 'Michelle' as first_name, 'Manson' as last_name, 2 as user_id, '2023-01-18' as order_date, 'delivered' as status),
        struct(4 as id, 'Edson' as first_name, 'Manson' as last_name, 2 as user_id, '2023-01-20' as order_date, 'pending' as status),
        struct(5 as id, 'Murilo' as first_name, 'Tanner' as last_name, 3 as user_id, '2023-01-22' as order_date, 'delivered' as status)
    ])
)
```

### ğŸ”— Camada stg: customers e orders
Modelos intermediÃ¡rios que selecionam e preparam os dados da tabela triggo_shop.

```sql
-- models/stg/customers.sql
select
    id as customer_id,
    first_name,
    last_name
from {{ ref('triggo_shop') }}
```

### ğŸ“Š Camada refined: customer_orders_summary
Modelo final que agrega dados de clientes e pedidos, pronto para ser consumido por ferramentas de BI.

```sql
-- models/refined/customer_orders_summary.sql
with customers as (
    select * from {{ ref('customers') }}
),

orders as (
    select * from {{ ref('orders') }}
),

customer_orders as (
    select
        customer_id,
        min(order_date) as first_order_date,
        count(order_id) as number_of_orders
    from orders
    group by 1
)

select
    customers.customer_id,
    customers.first_name,
    customers.last_name,
    customer_orders.first_order_date,
    customer_orders.number_of_orders
from customers
left join customer_orders using (customer_id)
```

Essa estrutura modular garante manutenÃ§Ã£o simplificada, clareza na lÃ³gica de negÃ³cio e execuÃ§Ã£o eficiente.

## ğŸ› ï¸ Como Replicar o Projeto
1. **Configure o GCP**
   - Crie um projeto no Google Cloud.
   - Ative a API do BigQuery.
   - **Importante**: Crie manualmente os conjuntos de dados (raw, stg, refined) no BigQuery.

2. **Credenciais para o dbt**
   - Crie uma conta de serviÃ§o no GCP.
   - Gere uma chave JSON com as permissÃµes necessÃ¡rias.
   - Salve as credenciais no arquivo `~/.dbt/profiles.yml`, configurando cada um dos destinos (raw, stg, refined).

3. **Configurar GitHub Actions**
   - Acesse o repositÃ³rio no GitHub.
   - Adicione a chave JSON como um segredo (ex.: `GCP_SERVICE_ACCOUNT`).

4. **Clone o RepositÃ³rio**
   ```bash
   git clone https://github.com/seu-usuario/seu-repositorio.git
   cd seu-repositorio
   ```
   Configure o arquivo `profiles.yml` localmente com suas credenciais e projeto GCP.

5. **Executar o Projeto**
   - **Localmente**:
     ```bash
     dbt build
     ```
     O comando `dbt build` irÃ¡ executar o `run` e `test` para todos os modelos, garantindo que a pipeline seja construÃ­da corretamente.
   - **Via GitHub Actions**: Os comandos serÃ£o executados automaticamente ao realizar um push.

## ğŸ“š DocumentaÃ§Ã£o
Gere a documentaÃ§Ã£o interativa com:
```bash
dbt docs generate && dbt docs serve
```

## âœ… BenefÃ­cios da SoluÃ§Ã£o
- ğŸ’¡ Foco em lÃ³gica de negÃ³cio, sem preocupaÃ§Ãµes com infraestrutura.
- ğŸ”’ Controle de qualidade com testes automatizados.
- ğŸ§© Modularidade e escalabilidade com dbt.
- ğŸš€ Deploy contÃ­nuo com GitHub Actions.

## ğŸ“¬ Contato
<p align="center">
<strong>Data Engineer - Danilo Gaspar</strong><br>
<a href="https://biolink.website/socialDG">ğŸ“§ Contact</a>
</p>